# HW1

## *Что было сделано*

В рамках  домашнего задания №1 мы работали с регрессией. Работу можно разделить на три части :
1. Разведочный анализ данных (EDA) и визуализация
2. Построение модели
3. Feature Engineering

Поговорим отдельно про каждую часть:

1. EDA + визуализация: для начала вспомнили некоторые базовые функции библитеки pandas (sample, head, tail). Затем посмотрели на основные статистики (как по числовым, там и по категориальным стотлбцам) с помощью метода describe. Потом перешли собственно к EDA: посчитали количество пропусков в каждом столбце и поличество дублирующихся строк. Удалили дубли из тренировочного датасета и обновили индексы. Затем перешли к преобразованию столбцов и заполнению пропусков: убрали единицы измерения для признаков mileage, engine, max_power, привели их к типу данных float и удалили столбец torque. Для заполнения пропусков использовали медиану по столбцу. Преобразование и заполнение проводили как для тренеровочного датасета, так и для тестового. Поменяли тип данных на int у столбцов engnine и seats и на этом EDA закончился.

   Перейдем к визуализации: отрисовали pairplot для тренировочного датасета, чтобы посмотреть как связаны признаки между собой и целевая переменная с признаками, сделали несколько выводов (подробнее в ноутбуке). Также отрисовали pairplot    для тестового датасета, чтобы убедиться, похожи ли датасеты. Но pairplot достаточно трудно анализировать, поэтому построили heatmap для числовых признаков. Из нее получили информацию, какие признаки наиболее коррелируют с переменной и    между собой. Построили scatter для наиболее скореллированной пары признаков (на трейне) - engine и max_power, а также scatter для seats и engine, так как связь между ними была неочевидной, а коэффициент корреляции второй по значению.

2. На втором этапе перешли к построению моделей: в рамках основного заданаия было построено 6 моделей, пять из которых обучались только на вещественных признаках, а одна на всех признаках, за исключением name. Поговорим немного о каждой модели:
   
  - LinearRegression с дефолтными параметрами, не будем на ней долго останавливаться. Зафиксируем только метрики качества:
    
   Метрики r2 и MSE для трейна: 0.5922591702157316 116874153930.02855

   Метрики r2 и MSE для теста: 0.5941419794788428 233298779730.45486
   
  - LinearRegression с дефолтными признаками + стандартизация: в качетсве стандартизатора был взят StandardScaler с дефолтными параметрами. Посмотрим на метрики качества:

   Метрики r2 и MSE для трейна: 0.5922591702157303 116874153930.02892

   Метрики r2 и MSE для теста: 0.594141979478852 233298779730.44965

   Как можно заметить, метрики практически не изменились. Однако уже на этом этапе удалось сделать вывод, какой признак наиболее информативный.

Для обучения всех остальных моделей использовались стандартизованнные данные.

   - Lasso-регрессия с дефолтными параметрами:

     Метрики r2 и MSE для трейна: 0.5922591702157303 116874153930.02892
 
     Метрики r2 и MSE для теста: 0.594141979478852 233298779730.44965

     Кроме того, на данном этапе ни одни признак не занулился, поэтому перешли к следующей модели:
     
   - Lasso-регрессия + подбор параметров с помощью GridSearchCV:

     Метрики r2 и MSE для трейна: 0.588810090610373 117862792376.97263
     
     Метрики r2 и MSE для теста: 0.580548891898135 241112474631.14008

     Качество немного ухудшилось, зато мы занулили один при признаков.

И финальная модель здесь:
   - ElasticNet + подбор параметров с помощью GridSearchCV:

     Метрики r2 и MSE для трейна: 0.5797455057759 120461049911.83008
     
     Метрики r2 и MSE для теста: 0.5506184969746151 258317320314.71527

Затем модель обучалась не только на вещественных призаках (которые были преобразованы с помощью StandardScaler), но и категориальных (которые были преобразованы с помощью OneHotEncoder):
   - Ridge регрессия + подбор параметров с помощью GridSearchCV:
     
      Метрики r2 и MSE для трейна: 0.665754773637673 95807496288.55307
   
      Метрики r2 и MSE для теста: 0.6348816134617712 209880474770.80933
   
Наконец-то мы смогли улучшить качество модели.

3. Feature Engineering: в рамках этой части было обучено две модели. Обе обучались только на вещественных признаках, посмотрим на каждую из них:
   
   - Добавление полиномиальных признаков + Ridge регрессия + подбор параметров с помощью GridSearchCV: качество модели удалось немного улучшить по сравнению просто с Ridge регрессией и подбором параметров с помощью GridSearchCV.
        
        Метрики r2 и MSE для трейна: 0.6678935399768101 95194443858.96703
        
        Метрики r2 и MSE для теста: 0.6489700314484845 201782049808.27615
        
   - Удаление выбросов+ добавление полиномиальных признаков + Ridge регрессия + подбор параметров с помощью GridSearchCV: к сожалению, данная модель переобучилась, и не дала прироста качества.
## *Что дало наибольший буст в качестве*

Максимальное улучшение в качестве дали генерация полиномиальных признаков и Ridge регрессия с подбор параметров с помощью GridSearchCV

## *Что сделать не вышло*

К сожалению, модель, которая принимала на вход очищенные от выбросов данные и генерировала полиномиальные признаки переобучилось. Скорее всего это произошло, потому что очищать признаки по 1 и 99 квантялям оказалось слишком радикальным решение для таких данных. 
